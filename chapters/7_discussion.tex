\documentclass[../main]{subfiles}
\begin{document}

\chapter{Discussion}
\label{ch:discussion}
In this chapter, we discuss the results of our experiments on clustering mutants.
First, we discuss the results of the first experiment. 
We will discuss the all results together and then compare the results between the experiments including and excluding the Levenshtein distance characteristic.
Second we will discuss the results of the second experiment and compare them to those of the first.
And last we will discuss the practicality of our research.

\section{RQ 1: Identifying and clustering mutant characteristics}
The maximum deviation from the original mutation score, for all variants(with and without Levenshtein distance) of the experiment, is below the statistical threshold.
As hypothesised we observe that it is possible to cluster mutants with the set of characteristics we identified while maintaining effectiveness and reducing the amount executed.
The hypothesis holds for all the projects and variants of the experiment.
66\% of the displayed results have a deviation of less than 1\%. 
This includes both variations of the experiment.
\newline
The results prove that the relations between the mutants represented by the characteristics we identified can be used to cluster mutants efficiently. 
This can be explained by the correlation between the result of a mutant, the calculated euclidean distance and the distance threshold(linkage criteria) used to decide whether a mutants should be clustered together.
\newline
If two mutants are grouped it is \textit{n} percent likely that the mutants have the same result where \textit{n} is the cluster accuracy.
\begin{finding}
    When executing 25\% of the total amount of mutants we can still maintain effectiveness.
\end{finding}
In both variations of the experiment we observe a reduction in average accuracy when increasing the performance by reducing the number of clusters.
These reductions are 0.1\% and 0.04\% for clustering with and without Levenshtein distance respectively.
We can also see that the average cluster accuracy is lower when reducing the amount executed.
\begin{finding}
    The more you reduce the number of mutants executed the more accuracy is lost.
\end{finding}
The results show that the average accuracy for reductions of 25\% and 50\% is the same.
This observation shows true for both variants of the experiment which is remarkable.
\begin{finding}
    We can reduce the number of mutants executed in our data set up to 50\% before losing more accuracy.
\end{finding}
It is also remarkable to see the min and max accuracy of the all clusters are 50\% to 100\% respectively.
Based on these results we can state the following:
\begin{itemize}
    \item For every project there was at least one cluster that consisted only of killed or survived mutants.
    \item For every project there was at least one cluster that evenly divided between killed and survived mutants.
\end{itemize}
With the exception of Google Auto Service and Commons Text, a reduction of 25\% and all characteristics, all projects showed an average accuracy above 90\%.
The combination of hierarchical clustering and the identified characteristics results in high accuracy clusters.
\newline
According the rules of logic, a higher cluster accuracy means a score closer to that of the original.
In other words if all clusters had an accuracy of 100\% we will achieve the same mutation score as that of the full set.
However we do not observe this behaviour in our results.
This is due to our random sampling method.
If we would select a mutant in the majority of each cluster the accuracy per cluster would correlate to the deviation in mutation score.
Unfortunately we do not know the majority of a cluster as we do now know if a mutant survives or is killed before execution.
\begin{finding}
    Random sampling a mutant per cluster may result in a bigger deviation between original score and weighted score.
\end{finding}
As stated in Chapter \ref{ch:results_rq1} the calculation of the Levenshtein distance characteristic took a long time.
For this reason we repeated the experiment without the Levenshtein distance characteristic.
Comparing the results between these variants we can observe a max deviation of 0.05\% between average difference of the mutation scores.
In 66\% of the results displayed in Chapter \ref{ch:results_rq1} clustering without the Levenshtein distance is more accurate.
The biggest difference in mutation score measured between all the projects and their reductions is 3.63\%.
Clustering without Levenshtein distance characteristic is on average more accurate.
\begin{finding}
    While clustering without the Levenshtein distance characteristic was more accurate in our results, the Levenshtein distance characteristic does not significantly increase or decrease the cluster accuracy.
\end{finding}

\section{RQ 2: Training a machine learning model and clustering mutant characteristics}
The maximum deviation from the original mutation score, for all variants(with and without Levenshtein distance characteristic) of the experiment, is above the statistical threshold.
The biggest deviation measured is 22.39\%.
This is significantly higher than the biggest deviation measured in the first experiment.
56\% of the results of both variants had a deviation in mutation score bigger than 5\%.
\begin{finding}
Our hypothesis does not hold for the clustering the mutants with the \acrshort{fcm} model trained in our experiment.
\end{finding}
We observe that the number of clusters does not have an obvious relation to the total amount of mutants. 
This is expected as the subtractive clustering does not look at the total amount of data points(mutants) but to the contents(characteristics) of the data points.
The number of clusters compared to the that of the hierarchical clustering is significantly lower.
While we do not know the exact clusters centroids the subtractive model calculated, a low number of clusters indicates close relationships between certain mutants.
\begin{finding}
The mutants represented as characteristics in our data set per project have, according to the subtractive clustering model, close relationships to certain other mutants in the same data set.
\end{finding}
We observe that the minimum lowest minimum cluster accuracy measured over all variants and projects is 50.54\% with and average of 62\%. 
This is higher than the minimum of the hierarchical clustering.
This means that in all project there was not one cluster that was evenly divided.
While the minimum accuracy was higher, the maximum accuracy was lower compared to the maximum accuracy of the hierarchical clustering results.
The highest accuracy measured over all variants and projects is 97.80\% with an average of 83.79\%
This means that in all project there was not one cluster that consisted of only survived or killed mutants.
\begin{finding}
The overall accuracy of the clusters generated by the \acrshort{fcm} model in both variants is lower compared to that of the hierarchical clustering.
\end{finding}
When we compare the accuracy per project between the \acrshort{fcm} model and hierarchical clustering we can observe that the lower accuracy of the \acrshort{fcm} model clusters have a higher impact on the deviation in mutation score.
This is caused by the relatively low number of clusters.
One cluster contains more mutants which results in a bigger weight per cluster.
\begin{finding}
The inaccuracy of clusters has a bigger impact on mutation score when the number of clusters is lower.
\end{finding}



\section{Application}
The application of our research is limited to all software projects written in the language Java and the requirements of PIT\cite{pit}.
We can repeat our experiment for every java project that can be run by PIT.
The scope of the research done in the domain of mutation clustering(Chapter \ref{ch:related_work}) is a subset of the scope in our research.
With our research it is possible to cluster all the mutants used in other related research.
The extraction of mutants is build within the PIT plugin system which is a plug and play system.
Applying our research can be done in three steps.
The first step is to run PIT with the plugin to gather the characteristics.
Gathering the characteristics does not take more than a few minutes depending on the number of mutants generated.
The plugin also makes sure PIT exits without executing mutants after gathering the characteristics.
The second step is to run the script for either the \acrshort{fcm} model or the hierarchical clustering.
The last step is to run PIT again with the plugin to filter the mutants based on the results of the clustering.
It is possible to build all these steps into a DevOps pipeline to automate the process. 
The plugins and scripts needed for these steps are available in the code repository on Github\cite{rbasarat-repo}.

\section{Threats to validity}
In this section, we discuss the threats to internal validity, external validity and reliability.
\subsection{Internal validity}
\subsubsection{Equivalent mutants}
Equivalent mutants are mutants that are syntactically different but functionally identical.
These mutants influence the mutation score while giving the same result as their equivalent counterpart.
In our research equivalent mutants could give a false image of the accuracy of the clusters and the overall accuracy if such a mutant was randomly selected.
PIT contains some functionality for reducing equivalent mutants\cite{pit}.
We also reduced the chance of inaccuracy by repeating our experiment.

\subsubsection{Test set representativity}
The software projects we used in our research were systematically selected.
Chapter \ref{ch:project_selection} provides an indication but not a wide representation of industrial software projects.
The conclusions drawn regarding the increase in performance by reducing the mutants are based on the comparison between our own baseline measurements.
\newline
Another threat which is the result of the representation of our test set is the representation of the mutants.
While our data set contains around 1 million mutants we do not know if we have seen all mutants that exist.
This will always be a problem as it would be nearly impossible to cluster and mutation test every piece of Java code, that conforms to the requirements of our research, ever written.

\subsubsection{Project configuration}
Some tests may not be recognized by PIT due to some external data required for the test.
Another reason may be that the tests uses global variables that are not available to PIT.
We encountered some of these tests in our data set.
While these tests did pass when run with only the unit test framework they would fail when run by PIT.
These projects still met the requirements stated in Chapter \ref{ch:project_selection}.
To solve this issue we removed these tests from the test suite.
By removing these specific tests we may have slightly, tough negligible, deviated from the individual real-world settings for respective projects.

\subsubsection{Expertise}
While this research is in the domain of software engineering it borrows techniques from data science.
The researcher's field of expertise is software engineering.
Since the researcher had to use techniques from different domains we can only guarantee that the research executed was done to the best of their ability.
Thus the research may contain sub optimal design choices which may have been made from a software engineering perspective.

\subsection{External validity}
We clustered mutants with two different techniques.
Our results are not generalisable to projects written in other programming languages as well as projects that cannot be run by PIT.
As a result of using PIT we limit ourselves to two testing frameworks; JUnit and TestNG.
PIT is still under active development and may expand its applicability, which in turn increases the applicability of this research.

\end{document}